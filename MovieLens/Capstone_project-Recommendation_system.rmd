---
title: "Capstone Project - Recommendation System"
author: "Renz Marvin S. Asprec"
date: "7/4/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
\newpage
```{r, echo=FALSE, message=FALSE, warning=FALSE}
##########################################################
# Create edx set, validation set (final hold-out test set)
##########################################################

# Note: this process could take a couple of minutes
if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")

library(tidyverse)
library(caret)
library(data.table)

# MovieLens 10M dataset:
# https://grouplens.org/datasets/movielens/10m/
# http://files.grouplens.org/datasets/movielens/ml-10m.zip

dl <- tempfile()
download.file("http://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)

ratings <- fread(text = gsub("::", "\t", readLines(unzip(dl, "ml-10M100K/ratings.dat"))),
                 col.names = c("userId", "movieId", "rating", "timestamp"))

movies <- str_split_fixed(readLines(unzip(dl, "ml-10M100K/movies.dat")), "\\::", 3)
colnames(movies) <- c("movieId", "title", "genres")

# if using R 4.0 or later:
movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(movieId),
                                           title = as.character(title),
                                           genres = as.character(genres))

movielens <- left_join(ratings, movies, by = "movieId")

# Validation set will be 10% of MovieLens data
set.seed(1, sample.kind="Rounding") # if using R 3.5 or earlier, use `set.seed(1)`
test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]

# Make sure userId and movieId in validation set are also in edx set
validation <- temp %>%
  semi_join(edx, by = "movieId") %>%
  semi_join(edx, by = "userId")

# Add rows removed from validation set back into edx set
removed <- anti_join(temp, validation)
edx <- rbind(edx, removed)

rm(dl, ratings, movies, test_index, temp, movielens, removed)

```
```{r, echo=FALSE, message=FALSE, warning=FALSE}
# install packages and load libraries
if(!require(knitr)) install.packages("knitr", repos = "http://cran.us.r-project.org")
if(!require(lubridate)) install.packages("lubridate", repos = "http://cran.us.r-project.org")
if(!require(tinytex)) install.packages("tinytex", repos = "http://cran.us.r-project.org")
if(!require(recosystem)) install.packages("recosystem", repos = "http://cran.us.r-project.org")

library(knitr)
library(lubridate)
library(tinytex)
library(recosystem)

# options
options(digits=5)
```

# Executive Summary
This project aims to produce a movie recommendation system, based on the [MoiveLens Dataset](www.https://grouplens.org/datasets/movielens/10m/), through different data analysis strategies via R.

The Movielens data set contains several ratings applied to different movies by many users of the online movie recommender service MovieLens. All users in the data were selected at random and had rated at least 20 movies.

Several approaches were performed in this project. The first approach was a baseline naive approach of just predicting the ratings using the average of all ratings. Then, different biases were investigated to improve the model. The effects of regularization to theses biases were also investigated. To further improve the model, matrix factorization method was also used.

Each approach was evaluated using the root mean squared (RMSE) loss function. 

The model which resulted to the least RMSE is the matrix factorization model, with an RMSE of 0.78818.

\newpage
# Introduction
## Movielens Data Set

Movielens data set is a collection of 10 million ratings and 100,000 tag applications applied to 10,000 movies by 72,000 users. This data set was released in January of 2009 by grouplens.

The users were selected at random for inclusion. All users have rated at least 20 movies.

The goal of this project is to create a movie recommendation system based on this data set.

## Evaluation Metrics
The resulting models in this project would be evaluated using the loss function, root mean squared error or RMSE. 

$$\mbox{RMSE} = \sqrt{\frac{1}{N}\sum_{u,i}(\hat{y}_{u,i}-{y}_{u,i})^2}$$

where ${y}_{u,i}$ is the rating for the user $u$, and movie $i$, and $\hat{y}_{u,i}$ is the notation for our predicted rating.

```{r, echo=FALSE}
RMSE<- function(rating_true, rating_predicted){
  sqrt(mean((rating_true-rating_predicted)^2))
}
```

# Methodology
## Exploratory Data Analsyis  

The movielens data was extracted from the [grouplens website](https://grouplens.org/datasets/movielens/10m/). The data was partitioned to a 90% training data set, _edx_, and a 10% final hold-out testing data set, _validation_. (Please refer to the Appendix for the code of movielens data extraction)

We can see the _edx_ training data in a tidy format below:

```{r, echo=FALSE}
as_tibble(edx)
```
From the tibble above, we can see that the data contains the following details in the columns:  

* userId - unique identification for a specific user  
* movieId - unique identification for a specific movie  
* rating - rating provided by a specific user for a specific movie. The rating is a 0-5 scale  
* timestamp - timestamp of the rating  
* title - movie title rated by the specific user  
* genres - genres associated with the movie  

```{r, echo =FALSE, fig.align="center", fig.width=6, fig.height=6}
# number of rows and columns
n_rows<- nrow(edx)
n_cols<- ncol(edx)

# no of unique users
n_users<- edx %>% 
  select(userId) %>%
  distinct() %>%
  summarize(n=n())

# no of unique movies
n_movies<- edx %>%
  select(movieId) %>%
  distinct() %>%
  summarize(n=n())

# list of genres
l_genres<- edx %>% separate_rows(genres, sep="\\|") %>%
  select(genres) %>%
  distinct() 
```

Our exploration of the data shows that there are `r n_rows` rows and `r n_cols` columns. There are `r n_users` unique users, `r n_movies` unique movies, and `r l_genres %>% summarize(n=n())` unique genres (including no assigned genres). 

Below is the list of the genres:
```{r, echo= FALSE}
l_genres %>% kable()
```

The ratings are in a scale of 0-5 stars. Below is a distribution of the ratings:

```{r, echo= FALSE, fig.align="center", fig.width=6, fig.height=6}
# distribution of ratings
edx %>%
  select(rating) %>%
  ggplot(aes(rating)) +
  geom_histogram(binwidth=0.5, color="black")
```
We can see that the whole star ratings are more common than half star ratings.

```{r, echo=FALSE}
edx_date<- edx %>%
  mutate(date=as_datetime(timestamp)) %>%
  select(-timestamp)
```

Exploration of the data shows that the ratings available are within the years `r year(range(edx_date$date))[1]` and `r year(range(edx_date$date))[2]`

\newpage

## Models
### Baseline - Naive Approach
#### Prediction of ratings based on mean  
Based on our intuition, we know that the easiest estimate that would reduce the value of the RMSE is the mean. Thus, our first model predicts the rating as the mean of all ratings in our data set. A model that predicts the mean would look like this:

$$\mbox{Y}_{u,i} = \mu + \epsilon_{u,i} $$
with $\mu$ as the average, and $\epsilon_{u,i}$ as the independent errors

### Movie Bias 
#### Prediction of rating based on mean, and movie bias  
This second model assumes that there is a bias for each movies. Some movies are just generally rated higher or lower than other movies. Such model would look like this:

$$\mbox{Y}_{u,i} = \mu + b_{i} + \epsilon_{u,i} $$
where $b_{i}$ is the bias for each movie, $i$.

### User Bias
#### Prediction of rating based on mean, movie bias, and user bias  
This third model assumes that there is a bias for each user. Some users generally rate lower or higher compared to other users. Such model would look like this:

$$\mbox{Y}_{u,i} = \mu + b_{i} + b_{u} +\epsilon_{u,i} $$
where $b_{u}$ is the bias for each user, $u$.

### Genre Bias
#### Prediction of rating based on mean, movie bias, and genre bias
This fourth model assumes that there is a bias for each genre. Some genres are preferred by some users more than the others. Such model would look like this:

$$\mbox{Y}_{u,i} = \mu + b_{i} + b_{u} + b_{u,g}+\epsilon_{u,i} $$
where $b_{u,g}$ is the bias for user, $u$, for a specific genre, $g$.

### Regularized Movie Bias
#### Penalize large estimates of $b_{i}$ formed from small sample sizes

The previous linear models did not account for movies that only have a few ratings. These movies with few ratings tend to have more uncertainty. In relation, we want to penalize these movie data that are few in samples, but provide high value of $b_{i}$s.

We penalize them through the following:

$$\sum_{u,i}(y_{u,i}-\mu-b_{i})^2 + \lambda \sum_{i}b_{i}^2 $$
where the second term is a penalty term  
In order to optimize the equation above, we compute the value of $b_{i}$ as

$$\hat{b}_{i}(\lambda)=\frac{1}{\lambda+n_{i}}\sum_{u=1}^{n_i}(Y_{u,i}-\hat{\mu})$$

Here, $\lambda$ is an optimization parameter.

### Regularized User Bias
#### Penalize large estimates of $b_{u}$ formed from small sample sizes

Similar with the movies, some users have rated only a few number of times. These users with few ratings tend to have more uncertainty. In relation, we want to penalize these user data that are few in samples, but provide high value of $b_{u}$s.

### Regularized Genre Bias
#### Penalize large estimates of $b_{u,g}$ formed from small sample sizes

Similar with previous regularization approaches, we penalize $b_{u,g}s$ that are few in samples, but are high in value. 

### Matrix Factorization

A popular technique in solving a recommendation system is to use matrix factorization. The idea in matrix factorization is to estimate the whole matrix of rating $R_{mxn}$ by the product of two matrices with lower dimensions, $P_{kxm}$ and $Q_{kxn}$, such that

$$\mbox{R}\approx P'Q$$
Let $p_{u}$ be the $u$-th column of $P$, and $q_{v}$ be the $v$-th column of $Q$, then the rating given by the user $u$ on the movie $v$ would be predicted as $p'_{u}q_{v}$.

\newpage

# Results
## Baseline - Naive Approach

For this model, we will use our training data which we previously defined as, _edx_.
We compute the average, mu, of the data.
```{r, echo=FALSE}
mu<- mean(edx$rating)
```
```{r}
mu
```

This average would be our prediction for all the ratings. We can now compute the RMSE of our predicted ratings as compared to the ratings in the , _validation_ data set.

```{r, echo=FALSE}
rating_predicted<- mu
rmse<- RMSE(validation$rating,rating_predicted)
```
```{r}
rmse
```

We get an RMSE of **`r rmse`**. This means that our recommendation error would be larger than a star of rating.

```{r, echo=FALSE}
rmses_results<- data.frame(model= "Naive Approach: mean of all ratings", RMSE= rmse) 
rmses_results %>% kable()
```

## Movie Bias
```{r, echo=FALSE}
movie_averages<- edx %>%
  group_by(movieId) %>%
  summarize(b_i= mean(rating- mu))
```

We compute $b_{i}$ . A plot of $b_{i}$ is shown below. 
```{r, echo=FALSE, fig.align="center", fig.width=6, fig.height=6}
qplot(movie_averages$b_i, bins=10, color=I("black"), xlab="b_i")
```

The plot of $b_{}i$ shows that indeed, some movies are generally rated higher than others.  

```{r, echo=FALSE}
rating_predicted<- validation %>% 
  left_join(movie_averages, by="movieId") %>%
  mutate(prediction= mu + b_i) %>%
  pull(prediction)
```

Now, we calculate our predictions using this new model. The resulting RMSE is shown below:
```{r, echo=FALSE}
rmse<- RMSE(validation$rating, rating_predicted)
rmses_results<- bind_rows(rmses_results,
                          data.frame(model="Mean with movie bias", RMSE= rmse))
rmses_results %>% kable()
```
 
The resulting RMSE for this model is **`r rmse`**. This is an improvement compared to our previous model.  

## User Bias
```{r, echo=FALSE}
user_averages<- edx %>%
  left_join(movie_averages, by="movieId") %>%
  group_by(userId) %>%
  summarize(b_u = mean(rating-mu-b_i))
```

We compute $b_{u}$. A plot of $b_{u}$ is shown below.

```{r, echo=FALSE, fig.align="center", fig.width=6, fig.height=6}
qplot(user_averages$b_u, bins=10, color=I("black"), xlab="b_u")
```
The plot of $b_{u}$ shows that some users rate generally lower or higher compared to other users. Although, there's not much variability from 0. 

We can now predict our new ratings based on this model. The resulting RMSE is shown below:
```{r, echo=FALSE}
rating_predicted<- validation %>%
  left_join(movie_averages, by="movieId") %>%
  left_join(user_averages, by="userId") %>%
  summarize(prediction = mu+b_i+b_u) %>% 
  pull(prediction)

rmse<- RMSE(validation$rating, rating_predicted)
rmses_results<- bind_rows(rmses_results,
                          data.frame(model="Mean with movie bias and user bias", RMSE=rmse))
rmses_results %>% kable()
```

The resulting RMSE for our new model is **`r rmse`**. This is an improvement compared to our previous models.

## Genre Bias
```{r, echo=FALSE}
genre_averages<- edx %>%
  left_join(movie_averages, by="movieId") %>%
  left_join(user_averages, by="userId") %>%
  group_by(genres) %>%
  summarize(b_u_g = mean(rating-mu-b_i-b_u))
```

We compute $b_{u,g}$. The plot of $b_{u,g}$ is shown below:
```{r, echo=FALSE, fig.align="center", fig.width=6, fig.height=6}
qplot(genre_averages$b_u_g, bins=10, color=I("black"), xlab="b_u_g")
```
The plot above showed that, there's not much variability from 0.

```{r, echo=FALSE}
rating_predicted<- validation %>%
  left_join(movie_averages, by="movieId") %>%
  left_join(user_averages, by="userId") %>%
  left_join(genre_averages, by="genres") %>%
  summarize(prediction = mu+ b_i+b_u+b_u_g) %>%
  pull(prediction)
```

We can now predict the ratings for this model. The resulting RMSE is shown below.
```{r, echo=FALSE}
rmse<- RMSE(validation$rating, rating_predicted)
rmses_results<- bind_rows(rmses_results, data.frame(model="Mean with movie bias, user bias, and genre bias", RMSE=rmse))
rmses_results %>% kable()
```

The resulting RMSE for our new model is **`r rmse`**. Although an improvement, this model didn't contribute much into lowering the RMSE as we've initially seen from the plot of the variability of the $b_{u}$s. From this, we can see that the genre bias is not a big contributor in predicting the ratings.

## Regularized Movie Bias
Let's investigate the top 10 best and worst movies.

```{r, echo=FALSE}
mu<- mean(edx$rating)

# output movie titles
movie_titles <- edx %>% 
    select(movieId, title) %>%
    distinct()

# output top and bottom 10 movies according to estimate
top_movies<- movie_averages %>% 
  left_join(movie_titles, by="movieId") %>%
  arrange(b_i) %>% 
  slice(1:10)  %>% 
  pull(title)

bottom_movies<- movie_averages %>% 
  left_join(movie_titles, by="movieId") %>%
  arrange(desc(b_i)) %>% 
  slice(1:10)  %>% 
  pull(title)

# investigate number of ratings for the movies in top and bottom 10
top_10_count<- edx %>% 
  filter(title %in% top_movies) %>%
  group_by(title) %>%
  summarize(n=n()) %>%
  arrange(n)

bottom_10_count<- edx %>% filter(title %in% bottom_movies) %>%
    group_by(title) %>%
    summarize(n=n()) %>%
    arrange(n)
```

Top 10 movies
```{r, echo=FALSE}
top_10_count %>% kable()
```
Bottom 10 movies
```{r, echo=FALSE}
bottom_10_count %>% kable()
```

From the tables above, we can see that the best and worst movies were rated by only a very few users. We expect this since with just a few user rating them, the corresponding ratings have more uncertainty.  

It is important to note that in optimizing $\lambda$, we can't use the _validation_ data set. So, we would partition our _edx_ data set to an 80% and 20%, training, and testing sets respectively.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
ind<- createDataPartition(edx$rating, times=1, p=0.2, list=FALSE)
temp<- edx[ind]
train_set<- edx[-ind]

# make sure that all movieId, and userId in the test_set are in the train_set
test_set <- temp %>% 
  semi_join(train_set, by="movieId") %>%
  semi_join(train_set, by="userId")

# Add rows removed from test_set back into train_set
removed<- anti_join(temp, test_set)
train_set<- bind_rows(train_set,removed)
```

Here are the dimensions of the training, and testing sets.  
For the testing set:
```{r, echo=FALSE}
dim(test_set)
```

For the training set:
```{r, echo=FALSE}
dim(train_set)
```

We define a range of lambdas that would be used for optimization
```{r}
lambdas<- seq(0,10,0.1)
```

We compute the average, $\mu$ for the train_set
```{r, echo=FALSE}
mu<- mean(train_set$rating)
```
```{r}
mu
```

Then, we compute the RMSEs for each lambda. The plot of the resulting RMSEs vs lambdas is shown below.
```{r, echo=FALSE}
# function to compute for the rmses for the assumed lambdas
rmses_reg<- sapply(lambdas, function(l){
  
  # solves for the regularized_movie_averages
  movie_averages_reg<- train_set %>%
  group_by(movieId) %>%
  summarize(b_i_reg = sum(rating-mu)/(n()+l), n_i=n())
  
  # predict rating based on b_i_reg
  rating_predicted_reg<- test_set %>%
    left_join(movie_averages_reg, by="movieId") %>%
    summarize(prediction = mu+b_i_reg) %>%
    pull(prediction)
  
  # compute for rmse
  RMSE(test_set$rating, rating_predicted_reg)
})

```

```{r, echo=FALSE,fig.align="center", fig.width=6, fig.height=6}
qplot(lambdas,rmses_reg)
```

Obtain lambda which provides the minimum RMSE
```{r, echo=FALSE}
lambda<- lambdas[which.min(rmses_reg)]
```
```{r}
lambda
```

Now that we have the optimied $\lambda$, we can use this to compute for the RMSE based on the _validation_ set.

We recompute the average, $\mu$. Now, for the _edx_ data set
```{r, echo=FALSE}
#recompute average, mu, for the edx set
mu<- mean(edx$rating)
```
```{r}
mu
```

We can now compute the regularized movie bias. The resulting RMSE based on this model is shown below:
```{r, echo=FALSE}
# compute regularized movie bias, b_i_reg
movie_averages_reg<- edx %>%
  group_by(movieId) %>%
  summarize(b_i_reg= sum(rating-mu)/(n()+lambda), n_i=n())
```

```{r, echo=FALSE}
# predict rating based on b_i_reg
rating_predicted_reg<- validation %>%
  left_join(movie_averages_reg, by="movieId") %>%
  summarize(prediction = mu+b_i_reg) %>%
  pull(prediction)
```

```{r, echo=FALSE}
# compute for RMSE
rmse<- RMSE(validation$rating, rating_predicted_reg)
rmses_results<- bind_rows(rmses_results,
                          data.frame(model= "Mean with regularized movie bias", RMSE=rmse))
rmses_results %>% kable()
```

The resulting RMSE for this model is **`r rmse`**. This is an improvement compared to the mean with movie bias model, although by just a very small value. However, it is still less than what we got from the model with movie, user, and genre biases.

## Regularized User Bias
We can see below the top 10 users who rated the least number of times

```{r, echo=FALSE}
edx %>% group_by(userId) %>%
  summarize(count=n()) %>%
  arrange(count) %>%
  slice(1:10) %>%
  kable()
```

compared to the top 10 users who rated the most number of times
```{r, echo=FALSE}
edx %>% group_by(userId) %>%
  summarize(count=n()) %>%
  arrange(desc(count)) %>%
  slice(1:10) %>%
  kable()
```

Here, we can see that some users rate less compared to other users.

Proceeding with the computation of regularized user bias, we now optimize the penalty term, lambda, through cross-validation.
```{r, echo=FALSE}
# range of lambdas used for optimization
lambdas<- seq(0,10,0.1)

# compute for regularized b_u 
mu<- mean(train_set$rating)

# compute RMSES
rmses_reg<- sapply(lambdas, function(l){
  
  # compute for b_i_reg
  movie_averages_reg<- train_set %>%
    group_by(movieId) %>%
    summarize(b_i_reg = sum(rating-mu)/(n()+l), n_i=n())
  
  # compute for b_u_reg
  user_averages_reg<- train_set %>%
    left_join(movie_averages_reg, by="movieId") %>%
    group_by(userId) %>%
    summarize(b_u_reg = sum(rating-mu-b_i_reg)/(n()+l))
  
  # predict ratings
  rating_predicted_reg<- test_set %>%
    left_join(movie_averages_reg, by="movieId") %>%
    left_join(user_averages_reg, by="userId") %>%
    summarize(prediction = mu+b_i_reg+b_u_reg) %>%
    pull(prediction)
  
  # compute RMSE
  RMSE(test_set$rating, rating_predicted_reg)
})
```

Here we can see the plot of the RMSEs vs the lambdas
```{r, echo=FALSE, fig.align="center", fig.width=6, fig.height=6}
# plot lambdas vs rmses
qplot(lambdas,rmses_reg)
```

We obtain the lambda that minimizes the RMSE.
```{r, echo=FALSE}
# obtain lambda that minimizes the rmses of the assigned test_set within the edx data
lambda<- lambdas[which.min(rmses_reg)]
```
```{r}
lambda
```

Once we optimized our lambda, we can now compute the regularized user bias. The resulting RMSE is shown below:
```{r, echo=FALSE}
# compute the RMSE of the validation set based on the optimized lambda
mu<- mean(edx$rating)

# compute for b_i_reg
movie_averages_reg<- edx %>%
  group_by(movieId) %>%
  summarize(b_i_reg = sum(rating-mu)/(n()+lambda), n_i=n())

# compute for b_u_reg
user_averages_reg<- edx %>%
  left_join(movie_averages_reg, by="movieId") %>%
  group_by(userId) %>%
  summarize(b_u_reg = sum(rating-mu-b_i_reg)/(n()+lambda)) 

# predict rating
rating_predicted_reg<- validation %>%
  left_join(movie_averages_reg, by="movieId") %>%
  left_join(user_averages_reg, by="userId") %>%
  summarize(prediction = mu+b_i_reg+b_u_reg) %>%
  pull(prediction)
# compute for RMSE based on the edx and validation data set
rmse<- RMSE(validation$rating,rating_predicted_reg)
rmses_results<- bind_rows(rmses_results,
                          data.frame(model="Mean with regularized movie and user bias", RMSE=rmse))
rmses_results %>% kable()
```

The resulting RMSE for our this model is **`r rmse`**. This is an improvement compared to the mean with regularized movie bias model. However, when compared to the non-regularized model, it did not improve much.

## Regularized Genre Bias
Similar, with our previous approaches, we optimize lambda through cross-validation.

The plot below shows the resulting RMSEs vs lambdas:

```{r, echo=FALSE}
# range of lambdas used for optimization
lambdas<- seq(0,10,0.1)

mu<- mean(train_set$rating)
rmses_reg<- sapply(lambdas, function(l){
  # compute for b_i
  movie_averages_reg<- train_set %>%
    group_by(movieId) %>%
    summarize(b_i_reg= sum(rating-mu)/(n()+l), n_i=n())
  
  # compute for b_u
  user_averages_reg<- train_set %>%
    left_join(movie_averages_reg, by="movieId") %>%
    group_by(userId) %>%
    summarize(b_u_reg = sum(rating-mu-b_i_reg)/(n()+l))
  
  # compute for b_u_g
  genre_averages_reg<- train_set %>%
    left_join(movie_averages_reg, by="movieId") %>%
    left_join(user_averages_reg, by="userId") %>%
    group_by(genres) %>%
    summarize(b_u_g_reg= sum(rating-mu-b_i_reg-b_u_reg)/(n()+l))
  
  # prediction based on test_set obtained from the edx data set
  rating_predicted_reg<- test_set %>%
    left_join(movie_averages_reg, by="movieId") %>%
    left_join(user_averages_reg, by="userId") %>%
    left_join(genre_averages_reg, by="genres") %>%
    summarize(prediction = mu+b_i_reg+b_u_reg+b_u_g_reg) %>%
    pull(prediction)
  
  # compute for RMSE
  RMSE(test_set$rating, rating_predicted_reg)
})

```

```{r, echo=FALSE, fig.align="center", fig.width=6, fig.height=6}
# plot of the resulting RMSEs vs lambdas
qplot(lambdas, rmses_reg) 
```

The lambda which minimizes the RMSE is
```{r, echo=FALSE}
# obtain lambda that minimizes the rmses of the assigned test_set within the edx data
lambda<- lambdas[which.min(rmses_reg)]
```
```{r}
lambda
```

We can now proceed with computing the regularized genre bias, based on the _edx_ data set. The resulting RMSE is shown below:
```{r, echo=FALSE}
# compute the RMSE of the validation set based on the optimized lambda
mu<- mean(edx$rating)

# compute for b_i
movie_averages_reg<- edx %>%
  group_by(movieId) %>%
  summarize(b_i_reg = sum(rating-mu)/(n()+lambda), n_i=n())

# compute for b_u
user_averages_reg<- edx %>%
  left_join(movie_averages_reg, by="movieId") %>%
  group_by(userId) %>%
  summarize(b_u_reg = sum(rating-mu-b_i_reg)/(n()+lambda))

# compute for b_u_g
genre_averages_reg<- edx %>%
  left_join(movie_averages_reg, by="movieId") %>%
  left_join(user_averages_reg, by="userId") %>%
  group_by(genres) %>%
  summarize(b_u_g_reg = sum(rating-mu-b_i_reg-b_u_reg)/(n()+lambda))

# predict rating based on the edx and validation data set
rating_predicted_reg<- validation %>%
  left_join(movie_averages_reg, by="movieId") %>%
  left_join(user_averages_reg, by="userId") %>%
  left_join(genre_averages_reg, by="genres") %>%
  summarize(prediction= mu+b_i_reg+b_u_reg+b_u_g_reg) %>%
  pull(prediction)

# compute for RMSE
rmse<- RMSE(validation$rating, rating_predicted_reg)
rmses_results<- bind_rows(rmses_results, 
                          data.frame(model="Mean and regularized movie, user, and genre bias", RMSE=rmse))

rmses_results%>% kable()
```
The resulting RMSE for this model is **`r rmse`**. This is an improvement compared to the mean with movie bias model, although by just a very small value. Moreover, when compared to the non-regularized model, it did not improve much.

## Matrix Factorization
To approach this problem, we can convert the data to a matrix of size equal to the no. of unique users by the no. of unique movies. However, this would be memory intensive. The _recosystem_ package in R allows us to perform matrix factorization without crashing our system.

The resulting RMSE for this approach is shown below:
```{r, echo=FALSE}
# Matrix factorization using recosystem
# Convert edx and validation sets to recosystem input format
edx_reco <-  with(edx, data_memory(user_index = userId, 
                                   item_index = movieId, 
                                   rating     = rating))
validation_reco  <-  with(validation,  data_memory(user_index = userId,
                                                   item_index = movieId, 
                                                   rating     = rating))
# construct recommender system object
r <- Reco()

# set parameters
opts_tune<- r$tune(edx_reco)$min

# tuning model parameters
r$train(edx_reco, opts = opts_tune)

# predict ratings based on validation data
rating_predicted<- r$predict(validation_reco, out_memory())

rmse<- RMSE(validation$rating, rating_predicted)
rmses_results<- bind_rows(rmses_results,
                          data.frame(model= "Matrix Factorization", 
                                     RMSE= rmse)
                          )
rmses_results %>% kable()
```

The resulting RMSE for this model is **`r rmse`**. This is a significant improvement from our previous models.


\newpage

# Conclusion

For this project, we've explored 8 different models in total. Our first approach is the baseline approach of just predicting the mean of all the ratings. We then investigated the effect of different biases such as movie, user, and genre biases. We saw that taking these biases into account improved our RMSE. In relation, we saw that the movie and user biases contributed more to minimizing the RMSE compared to the genre bias. 

We then investigated the effect of regularization to our models. Regularization generally improved the resulting RMSE. However, it did not improve it by much. 

Lastly, we used matrix factorization in predicting the ratings. Among the models, this is the most computer-intensive, but also significantly reduced the resulting RMSE.

The model which produced the least RMSE is the **matrix factorization** model with an RMSE of **`r rmses_results[8,2]`**.

## Limitations

The recommendation system methods investigated here in this project does not account for new users. New users have no existing information to use as basis for recommendation. Moreover, every time a new movie or user is added, the data should be rerun to take these new data into account.

\newpage

# Appendix

## Code provided by edx: 

```{r, eval=FALSE}
##########################################################
# Create edx set, validation set (final hold-out test set)
##########################################################

# Note: this process could take a couple of minutes
if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")

library(tidyverse)
library(caret)
library(data.table)

# MovieLens 10M dataset:
# https://grouplens.org/datasets/movielens/10m/
# http://files.grouplens.org/datasets/movielens/ml-10m.zip

dl <- tempfile()
download.file("http://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)

ratings <- fread(text = gsub("::", "\t", readLines(unzip(dl, "ml-10M100K/ratings.dat"))),
                 col.names = c("userId", "movieId", "rating", "timestamp"))

movies <- str_split_fixed(readLines(unzip(dl, "ml-10M100K/movies.dat")), "\\::", 3)
colnames(movies) <- c("movieId", "title", "genres")

# if using R 4.0 or later:
movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(movieId),
                                           title = as.character(title),
                                           genres = as.character(genres))

movielens <- left_join(ratings, movies, by = "movieId")

# Validation set will be 10% of MovieLens data
set.seed(1, sample.kind="Rounding") # if using R 3.5 or earlier, use `set.seed(1)`
test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]

# Make sure userId and movieId in validation set are also in edx set
validation <- temp %>%
  semi_join(edx, by = "movieId") %>%
  semi_join(edx, by = "userId")

# Add rows removed from validation set back into edx set
removed <- anti_join(temp, validation)
edx <- rbind(edx, removed)

rm(dl, ratings, movies, test_index, temp, movielens, removed)
```

## Code by user:
```{r, eval=FALSE}
# install packages and load libraries
if(!require(knitr)) install.packages("knitr", repos = "http://cran.us.r-project.org")
if(!require(lubridate)) install.packages("lubridate", repos = "http://cran.us.r-project.org")
if(!require(tinytex)) install.packages("tinytex", repos = "http://cran.us.r-project.org")
if(!require(recosystem)) install.packages("recosystem", repos = "http://cran.us.r-project.org")

library(knitr)
library(lubridate)
library(tinytex)
library(recosystem)

# options
options(digits=5)

# Initial exploration of the data----
as_tibble(edx)

# no of unique users
n_users<- edx %>% select(userId) %>%
  distinct() %>%
  summarize(n=n())

# list of genres
l_genres<- edx %>% separate_rows(genres, sep="\\|") %>%
  select(genres) %>%
  distinct()
l_genres %>% kable()

# no of genres
l_genres %>% summarize(n=n())

# distribution of ratings
edx %>%
  select(rating) %>%
  ggplot(aes(rating)) +
  geom_histogram(binwidth=0.5, color="black")

# convert timestamp to date format
edx_date<- edx %>%
  mutate(date=as_datetime(timestamp)) %>%
  select(-timestamp)

# year range of the ratings
year(range(edx_date$date))

# create evaluation metrics, RMSE
RMSE<- function(rating_true, rating_predicted){
  sqrt(mean((rating_true-rating_predicted)^2))
}
# Naive Approach - Prediction of rating based on the average of all ratings ---------------
# compute the average of all ratings
mu<- mean(edx$rating)

# perform rating prediction based on the average of all ratings
rating_predicted<- mu

# resulting rmse
rmse<- RMSE(validation$rating,rating_predicted)

# table of rmses
rmses_results<- data.frame(model= "Naive Approach: mean of all ratings", RMSE= rmse) 


# Movie bias - Prediction of rating based on the average ratings and a movie bias, b_i-----
# compute the average of all ratings
mu<- mean(edx$rating)

# compute b_i by averaging the residuals for each movie
movie_averages<- edx %>%
  group_by(movieId) %>%
  summarize(b_i= mean(rating- mu))

# plot of b_i
qplot(movie_averages$b_i, bins=10, color=I("black"), xlab="b_i")

# predict rating taking into account the movie bias, b_i
rating_predicted<- validation %>% 
  left_join(movie_averages, by="movieId") %>%
  mutate(prediction= mu + b_i) %>%
  pull(prediction)

# compute the RMSE taking into account the movie bias, b_i
rmse<- RMSE(validation$rating, rating_predicted)
rmses_results<- bind_rows(rmses_results,
                          data.frame(model="Mean with movie bias", RMSE= rmse))

# User-bias - Prediction of rating based on the average ratings, a movie bias, b_i, and a user bias, b_u----

# compute average for all ratings
mu<- mean(edx$rating)

# compute b_u by averaging the residuals(including the bias on movies) for each user
user_averages<- edx %>%
  left_join(movie_averages, by="movieId") %>%
  group_by(userId) %>%
  summarize(b_u = mean(rating-mu-b_i))

# plot of b_u
qplot(user_averages$b_u, bins=10, color=I("black"), xlab="b_u")

# predict ratings taking into account movie bias, b_i, and user bias, b_u
rating_predicted<- validation %>%
  left_join(movie_averages, by="movieId") %>%
  left_join(user_averages, by="userId") %>%
  summarize(prediction = mu+b_i+b_u) %>% 
  pull(prediction)

# compute RMSE 
rmse<- RMSE(validation$rating, rating_predicted)
rmses_results<- bind_rows(rmses_results,
                          data.frame(model="Mean with movie bias and user bias", RMSE=rmse))

# Genre-bias Approach - Prediction of rating based on a movie-bias, b_i, user-bias, b_u, and genre-bias, b_u_g -----

# compute average for all ratings
mu<- mean(edx$rating)

# compute b_u_g by averaging the residuals (including the movie-bias, and user-bias)
genre_averages<- edx %>%
  left_join(movie_averages, by="movieId") %>%
  left_join(user_averages, by="userId") %>%
  group_by(genres) %>%
  summarize(b_u_g = mean(rating-mu-b_i-b_u))

# plot of b_u_g
qplot(genre_averages$b_u_g, bins=10, color=I("black"), xlab="b_u_g")

# predict ratings taking into account the movie bias, b_i, user bias, b_u, and genre bias, b_u_g
rating_predicted<- validation %>%
  left_join(movie_averages, by="movieId") %>%
  left_join(user_averages, by="userId") %>%
  left_join(genre_averages, by="genres") %>%
  summarize(prediction = mu+ b_i+b_u+b_u_g) %>%
  pull(prediction)

# compute RMSE taking
rmse<- RMSE(validation$rating, rating_predicted)
rmses_results<- bind_rows(rmses_results, data.frame(model="Mean with movie bias, user bias, and genre bias", RMSE=rmse))
  
# Regularized Movie bias Approach - Penalize large estimates of b_i formed from small sample sizes------

# mean of ratings from edx
mu<- mean(edx$rating)

# output movie titles
movie_titles <- edx %>% 
  select(movieId, title) %>%
  distinct()

# output top and bottom 10 movies according to estimate
top_movies<- movie_averages %>% 
  left_join(movie_titles, by="movieId") %>%
  arrange(b_i) %>% 
  slice(1:10)  %>% 
  pull(title)

bottom_movies<- movie_averages %>% 
  left_join(movie_titles, by="movieId") %>%
  arrange(desc(b_i)) %>% 
  slice(1:10)  %>% 
  pull(title)

# investigate number of ratings for the movies in top and bottom 10
top_10_count<- edx %>% 
  filter(title %in% top_movies) %>%
  group_by(title) %>%
  summarize(n=n()) %>%
  arrange(n)

bottom_10_count<- edx %>% filter(title %in% bottom_movies) %>%
  group_by(title) %>%
  summarize(n=n()) %>%
  arrange(n)

# output top and bottom 10 movies
top_10_count %>% kable()
bottom_10_count %>% kable()

# optimize the penalty, lambda (using only the training set, edx)
# cross-validation using 20% as test data. Create a train set and a test set based on the edx data, for the optimization of lambdas. Note: the validation set must not be used for the optimization of lambdas

ind<- createDataPartition(edx$rating, times=1, p=0.2, list=FALSE)
temp<- edx[ind]
train_set<- edx[-ind]

# make sure that all movieId, and userId in the test_set are in the train_set
test_set <- temp %>% 
  semi_join(train_set, by="movieId") %>%
  semi_join(train_set, by="userId")
  
# Add rows removed from test_set back into train_set set
removed<- anti_join(temp, test_set)
train_set<- bind_rows(train_set,removed)

# Dimensions of training and testing set
dim(test_set)
dim(train_set)

# range of lambdas used for optimization
lambdas<- seq(0,10,0.1)

# compute average, mu, for the train_set
mu<- mean(train_set$rating)

# function to compute for the rmses for the assumed lambdas
rmses_reg<- sapply(lambdas, function(l){
  
  # solves for the regularized_movie_averages
  movie_averages_reg<- train_set %>%
  group_by(movieId) %>%
  summarize(b_i_reg = sum(rating-mu)/(n()+l), n_i=n())
  
  # predict rating based on b_i_reg
  rating_predicted_reg<- test_set %>%
    left_join(movie_averages_reg, by="movieId") %>%
    summarize(prediction = mu+b_i_reg) %>%
    pull(prediction)
  
  # compute for rmse
  RMSE(test_set$rating, rating_predicted_reg)
})

# get lambda which provides the minimum rmse
lambda<- lambdas[which.min(rmses_reg)]

# plot rmse vs lambda
qplot(lambdas,rmses_reg)

#recompute average, mu, for the edx set
mu<- mean(edx$rating)

# compute regularized movie bias, b_i_reg
movie_averages_reg<- edx %>%
  group_by(movieId) %>%
  summarize(b_i_reg= sum(rating-mu)/(n()+lambda), n_i=n())

# predict rating based on b_i_reg
rating_predicted_reg<- validation %>%
  left_join(movie_averages_reg, by="movieId") %>%
  summarize(prediction = mu+b_i_reg) %>%
  pull(prediction)

# compute for RMSE
rmse<- RMSE(validation$rating, rating_predicted_reg)
rmses_results<- bind_rows(rmses_results,
                          data.frame(model= "Mean with regularized movie bias", RMSE=rmse))
rmses_results %>% kable()

# Regularized User bias approach - Penalize large estimates of b_i and b_u formed from small sample sizes------

# show the bottom 10 users based on number of ratings
edx %>% group_by(userId) %>%
  summarize(count=n()) %>%
  arrange(count) %>%
  slice(1:10) %>%
  kable()

# show top 10 users based on number of ratings
edx %>% group_by(userId) %>%
  summarize(count=n()) %>%
  arrange(desc(count)) %>%
  slice(1:10) %>%
  kable()

# optimize the penalty, lambda (using only the training set, edx)

# range of lambdas used for optimization
lambdas<- seq(0,10,0.1)

# compute for regularized b_u 
mu<- mean(train_set$rating)

# compute RMSEs
rmses_reg<- sapply(lambdas, function(l){
  
  # compute for b_i_reg
  movie_averages_reg<- train_set %>%
    group_by(movieId) %>%
    summarize(b_i_reg = sum(rating-mu)/(n()+l), n_i=n())
  
  # compute for b_u_reg
  user_averages_reg<- train_set %>%
    left_join(movie_averages_reg, by="movieId") %>%
    group_by(userId) %>%
    summarize(b_u_reg = sum(rating-mu-b_i_reg)/(n()+l))
  
  # predict ratings
  rating_predicted_reg<- test_set %>%
    left_join(movie_averages_reg, by="movieId") %>%
    left_join(user_averages_reg, by="userId") %>%
    summarize(prediction = mu+b_i_reg+b_u_reg) %>%
    pull(prediction)
  
  # compute RMSE
  RMSE(test_set$rating, rating_predicted_reg)
})

# plot lambdas vs rmses
qplot(lambdas,rmses_reg)

# obtain lambda that minimizes the rmses of the assigned test_set within the edx data
lambda<- lambdas[which.min(rmses_reg)]

# compute the RMSE of the validation set based on the optimized lambda
mu<- mean(edx$rating)

# compute for b_i_reg
movie_averages_reg<- edx %>%
  group_by(movieId) %>%
  summarize(b_i_reg = sum(rating-mu)/(n()+lambda), n_i=n())

# compute for b_u_reg
user_averages_reg<- edx %>%
  left_join(movie_averages_reg, by="movieId") %>%
  group_by(userId) %>%
  summarize(b_u_reg = sum(rating-mu-b_i_reg)/(n()+lambda)) 

# predict rating
rating_predicted_reg<- validation %>%
  left_join(movie_averages_reg, by="movieId") %>%
  left_join(user_averages_reg, by="userId") %>%
  summarize(prediction = mu+b_i_reg+b_u_reg) %>%
  pull(prediction)

# compute for RMSE based on the edx and validation data set
rmse<- RMSE(validation$rating,rating_predicted_reg)
rmses_results<- bind_rows(rmses_results,
                          data.frame(model="Mean with regularized movie and user bias", RMSE=rmse))
rmses_results %>% kable()

# Regularized genre-based approach - Penalize large estimates of b_i, b_u, and b_u_g formed from small sample sizes -----

# use training set and test set obtained from the edx data set to optimize lambda

# range of lambdas used for optimization
lambdas<- seq(0,10,0.1)

mu<- mean(train_set$rating)
rmses_reg<- sapply(lambdas, function(l){
  # compute for b_i
  movie_averages_reg<- train_set %>%
    group_by(movieId) %>%
    summarize(b_i_reg= sum(rating-mu)/(n()+l), n_i=n())
  
  # compute for b_u
  user_averages_reg<- train_set %>%
    left_join(movie_averages_reg, by="movieId") %>%
    group_by(userId) %>%
    summarize(b_u_reg = sum(rating-mu-b_i_reg)/(n()+l))
  
  # compute for b_u_g
  genre_averages_reg<- train_set %>%
    left_join(movie_averages_reg, by="movieId") %>%
    left_join(user_averages_reg, by="userId") %>%
    group_by(genres) %>%
    summarize(b_u_g_reg= sum(rating-mu-b_i_reg-b_u_reg)/(n()+l))
  
  # prediction based on test_set obtained from the edx data set
  rating_predicted_reg<- test_set %>%
    left_join(movie_averages_reg, by="movieId") %>%
    left_join(user_averages_reg, by="userId") %>%
    left_join(genre_averages_reg, by="genres") %>%
    summarize(prediction = mu+b_i_reg+b_u_reg+b_u_g_reg) %>%
    pull(prediction)
  
  # compute for RMSE
  RMSE(test_set$rating, rating_predicted_reg)
})

# plot of the resulting RMSEs vs lambdas
qplot(lambdas, rmses_reg) 

# obtain lambda which optimizes the RMSES
lambda<- lambdas[which.min(rmses_reg)]

# compute the RMSE of the validation set based on the optimized lambda
mu<- mean(edx$rating)

# compute for b_i
movie_averages_reg<- edx %>%
  group_by(movieId) %>%
  summarize(b_i_reg = sum(rating-mu)/(n()+lambda), n_i=n())

# compute for b_u
user_averages_reg<- edx %>%
  left_join(movie_averages_reg, by="movieId") %>%
  group_by(userId) %>%
  summarize(b_u_reg = sum(rating-mu-b_i_reg)/(n()+lambda))

# compute for b_u_g
genre_averages_reg<- edx %>%
  left_join(movie_averages_reg, by="movieId") %>%
  left_join(user_averages_reg, by="userId") %>%
  group_by(genres) %>%
  summarize(b_u_g_reg = sum(rating-mu-b_i_reg-b_u_reg)/(n()+lambda))

# predict rating based on the edx and validation data set
rating_predicted_reg<- validation %>%
  left_join(movie_averages_reg, by="movieId") %>%
  left_join(user_averages_reg, by="userId") %>%
  left_join(genre_averages_reg, by="genres") %>%
  summarize(prediction= mu+b_i_reg+b_u_reg+b_u_g_reg) %>%
  pull(prediction)

# compute for RMSE
rmse<- RMSE(validation$rating, rating_predicted_reg)
rmses_results<- bind_rows(rmses_results, 
                          data.frame(model="Mean and regularized movie, user, and genre bias", RMSE=rmse))

rmses_results%>% kable()

# Matrix factorization ----
# Matrix factorization using recosystem
# Convert edx and validation sets to recosystem input format
edx_reco <-  with(edx, data_memory(user_index = userId, 
                                   item_index = movieId, 
                                   rating     = rating))
validation_reco  <-  with(validation,  data_memory(user_index = userId,
                                                   item_index = movieId, 
                                                   rating     = rating))
# construct recommender system object
r <- Reco()

# set parameters
opts_tune<- r$tune(edx_reco)$min

# tuning model parameters
r$train(edx_reco, opts = opts_tune)

# predict ratings based on validation data
rating_predicted<- r$predict(validation_reco, out_memory())

rmse<- RMSE(validation$rating, rating_predicted)
rmses_results<- bind_rows(rmses_results,
                          data.frame(model= "Matrix Factorization", 
                                     RMSE= rmse)
)
rmses_results %>% kable
```

